{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "from google.cloud import bigquery\n",
    "from tqdm import tqdm\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/ccorbin/.config/gcloud/application_default_credentials.json' \n",
    "os.environ['GCLOUD_PROJECT'] = 'som-nero-phi-jonc101' \n",
    "\n",
    "client=bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bq_to_pandas(query, nrows, chunksize=500000):\n",
    "    offsets = [i for i in range(0, nrows, chunksize)]\n",
    "    df = pd.DataFrame()\n",
    "    for offset in tqdm(offsets):\n",
    "        query_str = query + \" LIMIT {chunksize} OFFSET {offset}\"\n",
    "        query_str = query_str.format(chunksize=chunksize, offset=offset)\n",
    "        query_job = client.query(query_str)\n",
    "        df_slice = query_job.result().to_dataframe()\n",
    "        df = pd.concat([df, df_slice])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:58<03:52, 58.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [01:49<02:43, 54.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [02:44<01:49, 54.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [03:36<00:54, 54.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [04:19<00:00, 51.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `mining-clinical-decisions.abx.feature_timeline_long` \n",
    "WHERE feature_type IN (\"Lab Results\", \"Flowsheet\")\n",
    "AND TIMESTAMP_ADD(observation_time, INTERVAL 14*24 HOUR) > index_time \n",
    "ORDER BY obs_num\n",
    "\"\"\"\n",
    "\n",
    "df = read_bq_to_pandas(query, nrows=2337767, chunksize=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600119"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(look_up_table):\n",
    "    \"\"\"Converts df look up table to dictionary for faster look up later\"\"\"\n",
    "    bin_val_dict = {}\n",
    "    for feature in look_up_table['features'].unique():\n",
    "        feature_bin_vals = look_up_table[look_up_table['features'] == feature]\n",
    "        for _bin in feature_bin_vals['bins'].unique():\n",
    "            if feature not in bin_val_dict:\n",
    "                bin_val_dict[feature] = {}\n",
    "                bin_val_dict[feature]['min'] = []\n",
    "                bin_val_dict[feature]['max'] = []\n",
    "\n",
    "            min_val_for_bin = feature_bin_vals[feature_bin_vals['bins'] == _bin]['value']['min'].values[0]\n",
    "            max_val_for_bin = feature_bin_vals[feature_bin_vals['bins'] == _bin]['value']['max'].values[0]\n",
    "\n",
    "            bin_val_dict[feature]['min'].append(min_val_for_bin)\n",
    "            bin_val_dict[feature]['max'].append(max_val_for_bin)\n",
    "    return bin_val_dict\n",
    "\n",
    "    \n",
    "def train_featurizer(df_train):\n",
    "    \"\"\"\n",
    "    Compute percent_ranks and generates a look up table of min and max bin values\n",
    "    Input : long form dataframe with features and value where value are the continuous values of labs / vitals\n",
    "    Output: look up table - dict of dict of lists (key1 = feature_name, key2 = max or min, values = lists of values)\n",
    "    \"\"\"\n",
    "    # Compute percentiles and bins\n",
    "    df_train['percentiles'] = df_train.groupby('features')['value'].transform(lambda x: x.rank(pct=True))\n",
    "    df_train['bins'] = df_train['percentiles'].apply(lambda x: int(x * 10))\n",
    "    \n",
    "    # Generate look up table and conver to dictionary stucture\n",
    "    look_up_table_df = df_train.groupby(['features', 'bins']).agg({'value' : ['min', 'max']}).reset_index()\n",
    "    look_up_table = convert_to_dict(look_up_table_df)\n",
    "    \n",
    "    ### Sanity Check. Ensure that min vector for each feature is strictly increasing (no ties!)\n",
    "    # Should be the case because ties are given same percentile rank in default pandas rank function\n",
    "    for feature in look_up_table:\n",
    "        mins = look_up_table[feature]['min']\n",
    "        for i in range(len(mins)-1):\n",
    "            assert mins[i] < mins[i+1]\n",
    "    \n",
    "    return look_up_table\n",
    "\n",
    "\n",
    "def apply_featurizer(df, look_up_table):\n",
    "    \n",
    "    def get_appropriate_bin(feature, value, look_up_table):\n",
    "        \"\"\"Takes in feature, value and look up table and returns appropriate bin\n",
    "\n",
    "        Quick Note: For some features, we do not have 10 bins.  This happens when we have many many ties in the \n",
    "        percent rank - and the percent rank alg returns ties as the average rank within that tie. So for instance\n",
    "        we're trying to break each feature up into deciles where each bin covers range of 10% of the examples. But if more\n",
    "        than 10% of the examples take on 1 value - then bins can be skipped. This shouldn't really be a problem\n",
    "        for downstream tasks - just something to be aware of. This also means 'bins' and 'bins_applied' won't have\n",
    "        perfect overlap in features that end up having less than 10 bins\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            mins = look_up_table[feature]['min']\n",
    "        except: # Feature not found in training set\n",
    "            return 0 # return 0th bin - this will get removed as a feature in downstream processing\n",
    "        for i in range(len(mins) - 1):\n",
    "            # If value is smaller than min value of smallest bin (in test time) - then return 0 (smallest bin)\n",
    "            if i == 0 and value < mins[i]:\n",
    "                return i\n",
    "\n",
    "            if value >= mins[i] and value < mins[i+1] :\n",
    "                return i\n",
    "\n",
    "        # Then in last bin\n",
    "        return len(mins)-1\n",
    "    \n",
    "    df['bins_applied'] = df[['features', 'value']].apply(\n",
    "        lambda x: get_appropriate_bin(x['features'], x['value'], look_up_table), axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment by validation split time\n",
    "df_train = df[df['index_time'] < '2018-01-01']\n",
    "\n",
    "# Train featurizer\n",
    "look_up_table = train_featurizer(df_train)\n",
    "\n",
    "# Apply featurizer\n",
    "df_featurized = apply_featurizer(df, look_up_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featurized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check in leui of test code for now\n",
    "df_train = apply_featurizer(df_train, look_up_table)\n",
    "look_up_table_df = df_train.groupby(['features', 'bins']).agg({'value' : ['min', 'max']}).reset_index()\n",
    "\n",
    "features_with_0_9_bins = []\n",
    "for feature in look_up_table_df:\n",
    "    num_bins = len(look_up_table_df[look_up_table_df['features'] == feature]['bins'].values)\n",
    "    ten_in_bins = 10 in look_up_table_df[look_up_table_df['features'] == feature]['bins'].values\n",
    "    if num_bins == 10 and not ten_in_bins:\n",
    "        features_with_0_9_bins.append(feature)\n",
    "\n",
    "for feature in features_with_0_9_bins:\n",
    "    df_test = df_train[df_train['features'] == 'feature']\n",
    "    for b_real, b_computed in zip(df_test['bins'].values, df_test['bins_applied'].values):\n",
    "        assert(b_real == b_computed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# House Cleaning\n",
    "columns = ['obs_num', 'anon_id', 'pat_enc_csn_id_coded', 'index_time', 'observation_time', 'feature_type', 'features', 'value', 'bins_applied']\n",
    "df_new = df_featurized[columns]\n",
    "\n",
    "# New feature names\n",
    "df_new['features'] = ['_'.join([x, str(y)]) for x, y in zip(df_new['features'].values, df_new['bins_applied'].values)] \n",
    "df_new['feature_type'] = [x + '_train' for x in df_new['feature_type'].values]\n",
    "df_new['value'] = [1 for x in df_new['value'].values] \n",
    "\n",
    "# df_new.to_csv('lab_results_vitals_binned.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_num</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>pat_enc_csn_id_coded</th>\n",
       "      <th>index_time</th>\n",
       "      <th>observation_time</th>\n",
       "      <th>feature_type</th>\n",
       "      <th>features</th>\n",
       "      <th>value</th>\n",
       "      <th>bins_applied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>2009-07-15 03:42:00+00:00</td>\n",
       "      <td>Lab Results_train</td>\n",
       "      <td>UPH_4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>2009-07-15 03:21:00+00:00</td>\n",
       "      <td>Lab Results_train</td>\n",
       "      <td>BUN_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>2009-07-10 18:57:00+00:00</td>\n",
       "      <td>Lab Results_train</td>\n",
       "      <td>BUN_2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>2009-07-10 19:20:00+00:00</td>\n",
       "      <td>Lab Results_train</td>\n",
       "      <td>PLT_4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>2009-07-15 03:10:00+00:00</td>\n",
       "      <td>Lab Results_train</td>\n",
       "      <td>EOSAB_8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obs_num   anon_id  pat_enc_csn_id_coded                index_time  \\\n",
       "0        1  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "1        4  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "2        5  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "3        6  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "4        8  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "\n",
       "           observation_time       feature_type features  value  bins_applied  \n",
       "0 2009-07-15 03:42:00+00:00  Lab Results_train    UPH_4      1             4  \n",
       "1 2009-07-15 03:21:00+00:00  Lab Results_train    BUN_1      1             1  \n",
       "2 2009-07-10 18:57:00+00:00  Lab Results_train    BUN_2      1             2  \n",
       "3 2009-07-10 19:20:00+00:00  Lab Results_train    PLT_4      1             4  \n",
       "4 2009-07-15 03:10:00+00:00  Lab Results_train  EOSAB_8      1             8  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600119"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
