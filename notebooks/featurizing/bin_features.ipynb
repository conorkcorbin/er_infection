{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/sw/open/anaconda/3/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "from google.cloud import bigquery\n",
    "from tqdm import tqdm\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/ccorbin/.config/gcloud/application_default_credentials.json' \n",
    "os.environ['GCLOUD_PROJECT'] = 'som-nero-phi-jonc101' \n",
    "\n",
    "client=bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bq_to_pandas(query, nrows, chunksize=500000):\n",
    "    offsets = [i for i in range(0, nrows, chunksize)]\n",
    "    df = pd.DataFrame()\n",
    "    for offset in tqdm(offsets):\n",
    "        query_str = query + \" LIMIT {chunksize} OFFSET {offset}\"\n",
    "        query_str = query_str.format(chunksize=chunksize, offset=offset)\n",
    "        query_job = client.query(query_str)\n",
    "        df_slice = query_job.result().to_dataframe()\n",
    "        df = pd.concat([df, df_slice])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:53<00:00, 46.78s/it]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    *\n",
    "FROM \n",
    "    `mining-clinical-decisions.abx.feature_timeline_long` \n",
    "WHERE \n",
    "    feature_type IN (\"Lab Results\", \"Flowsheet\")\n",
    "AND \n",
    "    TIMESTAMP_ADD(observation_time, INTERVAL 14*24 HOUR) > index_time \n",
    "ORDER BY\n",
    "    obs_num\n",
    "\"\"\"\n",
    "\n",
    "df = read_bq_to_pandas(query, nrows=2337767, chunksize=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600119"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(look_up_table):\n",
    "    \"\"\"Converts df look up table to dictionary for faster look up later\"\"\"\n",
    "    bin_val_dict = {}\n",
    "    for feature in look_up_table['features'].unique():\n",
    "        feature_bin_vals = look_up_table[look_up_table['features'] == feature]\n",
    "        for _bin in feature_bin_vals['bins'].unique():\n",
    "            if feature not in bin_val_dict:\n",
    "                bin_val_dict[feature] = {}\n",
    "                bin_val_dict[feature]['min'] = []\n",
    "                bin_val_dict[feature]['max'] = []\n",
    "\n",
    "            min_val_for_bin = feature_bin_vals[feature_bin_vals['bins'] == _bin]['value']['min'].values[0]\n",
    "            max_val_for_bin = feature_bin_vals[feature_bin_vals['bins'] == _bin]['value']['max'].values[0]\n",
    "\n",
    "            bin_val_dict[feature]['min'].append(min_val_for_bin)\n",
    "            bin_val_dict[feature]['max'].append(max_val_for_bin)\n",
    "    return bin_val_dict\n",
    "\n",
    "    \n",
    "def train_featurizer(df_train):\n",
    "    \"\"\"\n",
    "    Compute percent_ranks and generates a look up table of min and max bin values\n",
    "    Input : long form dataframe with features and value where value are the continuous values of labs / vitals\n",
    "    Output: look up table - dict of dict of lists (key1 = feature_name, key2 = max or min, values = lists of values)\n",
    "    \"\"\"\n",
    "    # Compute percentiles and bins\n",
    "    df_train['percentiles'] = df_train.groupby('features')['value'].transform(lambda x: x.rank(pct=True))\n",
    "    df_train['bins'] = df_train['percentiles'].apply(lambda x: int(x * 10))\n",
    "    \n",
    "    # Generate look up table and conver to dictionary stucture\n",
    "    look_up_table_df = df_train.groupby(['features', 'bins']).agg({'value' : ['min', 'max']}).reset_index()\n",
    "    look_up_table = convert_to_dict(look_up_table_df)\n",
    "    \n",
    "    ### Sanity Check. Ensure that min vector for each feature is strictly increasing (no ties!)\n",
    "    # Should be the case because ties are given same percentile rank in default pandas rank function\n",
    "    for feature in look_up_table:\n",
    "        mins = look_up_table[feature]['min']\n",
    "        for i in range(len(mins)-1):\n",
    "            assert mins[i] < mins[i+1]\n",
    "    \n",
    "    return look_up_table\n",
    "\n",
    "\n",
    "def apply_featurizer(df, look_up_table):\n",
    "    \n",
    "    def get_appropriate_bin(feature, value, look_up_table):\n",
    "        \"\"\"Takes in feature, value and look up table and returns appropriate bin\n",
    "\n",
    "        Quick Note: For some features, we do not have 10 bins.  This happens when we have many many ties in the \n",
    "        percent rank - and the percent rank alg returns ties as the average rank within that tie. So for instance\n",
    "        we're trying to break each feature up into deciles where each bin covers range of 10% of the examples. But if more\n",
    "        than 10% of the examples take on 1 value - then bins can be skipped. This shouldn't really be a problem\n",
    "        for downstream tasks - just something to be aware of. This also means 'bins' and 'bins_applied' won't have\n",
    "        perfect overlap in features that end up having less than 10 bins\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            mins = look_up_table[feature]['min']\n",
    "        except: # Feature not found in training set\n",
    "            return 0 # return 0th bin - this will get removed as a feature in downstream processing\n",
    "        for i in range(len(mins) - 1):\n",
    "            # If value is smaller than min value of smallest bin (in test time) - then return 0 (smallest bin)\n",
    "            if i == 0 and value < mins[i]:\n",
    "                return i\n",
    "\n",
    "            if value >= mins[i] and value < mins[i+1] :\n",
    "                return i\n",
    "\n",
    "        # Then in last bin\n",
    "        return len(mins)-1\n",
    "    \n",
    "    df['bins_applied'] = df[['features', 'value']].apply(\n",
    "        lambda x: get_appropriate_bin(x['features'], x['value'], look_up_table), axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/sw/open/anaconda/3/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/share/sw/open/anaconda/3/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Segment by validation split time\n",
    "df_train = df[df['index_time'] < '2018-01-01']\n",
    "\n",
    "# Train featurizer\n",
    "look_up_table = train_featurizer(df_train)\n",
    "\n",
    "# Apply featurizer\n",
    "df_featurized = apply_featurizer(df, look_up_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_num</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>pat_enc_csn_id_coded</th>\n",
       "      <th>index_time</th>\n",
       "      <th>order_id</th>\n",
       "      <th>feature_type</th>\n",
       "      <th>features</th>\n",
       "      <th>value</th>\n",
       "      <th>observation_time</th>\n",
       "      <th>bins_applied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>356295030</td>\n",
       "      <td>Lab Results</td>\n",
       "      <td>UPH</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2009-07-15 03:42:00+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>Flowsheet</td>\n",
       "      <td>Pulse_val_1</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2009-07-15 01:45:00+00:00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>356295028</td>\n",
       "      <td>Lab Results</td>\n",
       "      <td>BUN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2009-07-15 03:21:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>356110667</td>\n",
       "      <td>Lab Results</td>\n",
       "      <td>BUN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2009-07-10 18:57:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>356110666</td>\n",
       "      <td>Lab Results</td>\n",
       "      <td>PLT</td>\n",
       "      <td>176.0</td>\n",
       "      <td>2009-07-10 19:20:00+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obs_num   anon_id  pat_enc_csn_id_coded                index_time  \\\n",
       "0        1  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "1        2  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "2        4  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "3        5  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "4        6  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "\n",
       "    order_id feature_type     features  value          observation_time  \\\n",
       "0  356295030  Lab Results          UPH    6.0 2009-07-15 03:42:00+00:00   \n",
       "1          8    Flowsheet  Pulse_val_1  104.0 2009-07-15 01:45:00+00:00   \n",
       "2  356295028  Lab Results          BUN   10.0 2009-07-15 03:21:00+00:00   \n",
       "3  356110667  Lab Results          BUN   13.0 2009-07-10 18:57:00+00:00   \n",
       "4  356110666  Lab Results          PLT  176.0 2009-07-10 19:20:00+00:00   \n",
       "\n",
       "   bins_applied  \n",
       "0             3  \n",
       "1             7  \n",
       "2             1  \n",
       "3             2  \n",
       "4             3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_featurized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/sw/open/anaconda/3/lib/python3.6/site-packages/ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Sanity check in leui of test code for now\n",
    "df_train = apply_featurizer(df_train, look_up_table)\n",
    "look_up_table_df = df_train.groupby(['features', 'bins']).agg({'value' : ['min', 'max']}).reset_index()\n",
    "\n",
    "features_with_0_9_bins = []\n",
    "for feature in look_up_table_df:\n",
    "    num_bins = len(look_up_table_df[look_up_table_df['features'] == feature]['bins'].values)\n",
    "    ten_in_bins = 10 in look_up_table_df[look_up_table_df['features'] == feature]['bins'].values\n",
    "    if num_bins == 10 and not ten_in_bins:\n",
    "        features_with_0_9_bins.append(feature)\n",
    "\n",
    "for feature in features_with_0_9_bins:\n",
    "    df_test = df_train[df_train['features'] == 'feature']\n",
    "    for b_real, b_computed in zip(df_test['bins'].values, df_test['bins_applied'].values):\n",
    "        assert(b_real == b_computed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/sw/open/anaconda/3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/share/sw/open/anaconda/3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/share/sw/open/anaconda/3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# House Cleaning\n",
    "columns = ['obs_num', 'anon_id', 'pat_enc_csn_id_coded', 'index_time', 'observation_time', 'feature_type', 'features', 'value', 'bins_applied']\n",
    "df_new = df_featurized[columns]\n",
    "\n",
    "# New feature names\n",
    "df_new['features'] = ['_'.join([x, str(y)]) for x, y in zip(df_new['features'].values, df_new['bins_applied'].values)] \n",
    "df_new['feature_type'] = [x + '_train' for x in df_new['feature_type'].values]\n",
    "df_new['value'] = [None for x in df_new['value'].values] \n",
    "\n",
    "# df_new.to_csv('lab_results_vitals_binned.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_num</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>pat_enc_csn_id_coded</th>\n",
       "      <th>index_time</th>\n",
       "      <th>observation_time</th>\n",
       "      <th>feature_type</th>\n",
       "      <th>features</th>\n",
       "      <th>value</th>\n",
       "      <th>bins_applied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>2009-07-15 03:42:00+00:00</td>\n",
       "      <td>Lab Results_train</td>\n",
       "      <td>UPH_3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>2009-07-15 01:45:00+00:00</td>\n",
       "      <td>Flowsheet_train</td>\n",
       "      <td>Pulse_val_1_7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>2009-07-15 03:21:00+00:00</td>\n",
       "      <td>Lab Results_train</td>\n",
       "      <td>BUN_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>2009-07-10 18:57:00+00:00</td>\n",
       "      <td>Lab Results_train</td>\n",
       "      <td>BUN_2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>JCcce3e1</td>\n",
       "      <td>131002113973</td>\n",
       "      <td>2009-07-15 03:49:00+00:00</td>\n",
       "      <td>2009-07-10 19:20:00+00:00</td>\n",
       "      <td>Lab Results_train</td>\n",
       "      <td>PLT_3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obs_num   anon_id  pat_enc_csn_id_coded                index_time  \\\n",
       "0        1  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "1        2  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "2        4  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "3        5  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "4        6  JCcce3e1          131002113973 2009-07-15 03:49:00+00:00   \n",
       "\n",
       "           observation_time       feature_type       features  value  \\\n",
       "0 2009-07-15 03:42:00+00:00  Lab Results_train          UPH_3      1   \n",
       "1 2009-07-15 01:45:00+00:00    Flowsheet_train  Pulse_val_1_7      1   \n",
       "2 2009-07-15 03:21:00+00:00  Lab Results_train          BUN_1      1   \n",
       "3 2009-07-10 18:57:00+00:00  Lab Results_train          BUN_2      1   \n",
       "4 2009-07-10 19:20:00+00:00  Lab Results_train          PLT_3      1   \n",
       "\n",
       "   bins_applied  \n",
       "0             3  \n",
       "1             7  \n",
       "2             1  \n",
       "3             2  \n",
       "4             3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['order_id'] = [x for x in df_new['obs_num'].values]\n",
    "columns = ['obs_num', 'anon_id', 'pat_enc_csn_id_coded', 'index_time', 'order_id', 'feature_type', 'features', 'value', 'observation_time']\n",
    "df_new[columns].to_csv('binned_labs_vitals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[columns].to_csv('binned_labs_vitals.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
